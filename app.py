import streamlit as st
import pandas as pd
# import ollama
import json

# ======================
# Helper : LLM Call
# ======================
from src.llm_helper import ask_mistral


# ======================
# UI
# ======================
st.set_page_config(page_title="Analyse Formulaire IA", layout="wide")

st.sidebar.title("üß≠ Menu")
menu = st.sidebar.radio("Choisir une fonctionnalit√© :", 
                        ["D√©tection d'objectif", "R√©sum√© automatique", "Chatbot intelligent"])


# Initialisation
uploaded_file = None
# --------------------------------------
# 1. D√©tection d'objectif
# --------------------------------------
if menu == "D√©tection d'objectif":
    st.title("üéØ D√©tection de l‚Äôobjectif du formulaire")

    uploaded_file = st.file_uploader("Uploader un fichier CSV ou JSON contenant les questions", type=["csv", "json"])
    
if uploaded_file is not None:
    if uploaded_file.name.endswith(".csv"):
        df = pd.read_csv(uploaded_file)
        questions = df.iloc[:, 0].tolist()
    else:  # JSON
        data = json.load(uploaded_file)
        if isinstance(data, list):
            questions = data
        else:
            questions = data.get("questions", [])
    
    st.write("üìã Questions du formulaire :")
    for q in questions:
        st.markdown(f"- {q}")
        
    if st.button("Analyser l‚Äôobjectif"):
        prompt = f"""Voici un formulaire avec les questions suivantes : 
{questions}

D√©termine l‚Äôobjectif principal de ce formulaire parmi :
- Satisfaction client
- Analyse de performance de vente
- Planification d‚Äô√©v√©nement
- √âtude de march√©
- Autre (pr√©ciser)
"""
        result = ask_mistral(prompt)
        st.success(f"üîç Objectif d√©tect√© : {result}")


# --------------------------------------
# 2. R√©sum√© automatique
# --------------------------------------
elif menu == "R√©sum√© automatique":
    st.title("üìù R√©sum√© abstractif des r√©ponses ouvertes")

    uploaded_file = st.file_uploader("Uploader un fichier JSON contenant les r√©ponses ouvertes", type=["json"])
    
    if uploaded_file is not None:
        data = json.load(uploaded_file)
        responses = data.get("responses", [])

        st.write("üìã R√©ponses collect√©es :")
        for r in responses[:10]:  # afficher un √©chantillon
            st.markdown(f"- {r}")

        if st.button("G√©n√©rer le r√©sum√©"):
            prompt = f"""Voici un ensemble de r√©ponses ouvertes donn√©es par plusieurs utilisateurs : 
{responses}

Fais un r√©sum√© abstractif (en reformulant) des points principaux exprim√©s par les utilisateurs."""
            result = ask_mistral(prompt)
            st.success("üìù R√©sum√© g√©n√©r√© :")
            st.write(result)


# --------------------------------------
# 3. Chatbot intelligent
# --------------------------------------
elif menu == "Chatbot intelligent":
    st.title("ü§ñ Chatbot IA sur donn√©es de formulaire")

    uploaded_file = st.file_uploader(
        "Uploader un fichier CSV ou JSON contenant les donn√©es du formulaire",
        type=["csv", "json"]
    )

    # Historique dans la session
    if "history" not in st.session_state:
        st.session_state.history = []

    # Nettoyage anciens formats
    st.session_state.history = [msg for msg in st.session_state.history if isinstance(msg, dict)]

    if uploaded_file is not None:
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
            data_text = df.to_string()
        else:
            data = json.load(uploaded_file)
            data_text = json.dumps(data, indent=2, ensure_ascii=False)

        st.write("‚úÖ Donn√©es charg√©es.")

        # --------------------------
        # Affichage du chat
        # --------------------------
        chat_html = "<div style='height:400px; overflow-y:auto; padding:10px; border-radius:10px; background-color:#121212; display:flex; flex-direction:column;'>"

        for chat in st.session_state.history:
            if chat["role"] == "user":
                chat_html += f"""
                <div style='align-self:flex-end; background-color:#2F80ED; color:#fff; padding:8px; border-radius:12px; margin:5px 0; max-width:70%; word-wrap:break-word;'>{chat['message']}</div>"""
            else:
                chat_html += f"""
                <div style='align-self:flex-start; background-color:#333333; color:#fff; padding:8px; border-radius:12px; margin:5px 0; max-width:70%; word-wrap:break-word;'>{chat['message']}</div>"""

        chat_html += "</div>"
        st.markdown(chat_html, unsafe_allow_html=True)

        # --------------------------
        # Fonction pour envoyer un message
        # --------------------------
        def send_message():
            user_message = st.session_state.user_input.strip()
            if user_message:
                st.session_state.history.append({"role": "user", "message": user_message})

                # Prompt pour le mod√®le
                prompt = f"""Tu es un assistant IA qui r√©pond uniquement √† partir des donn√©es suivantes :
{data_text}

Question : {user_message}
R√©ponse :"""
                result = ask_mistral(prompt)

                st.session_state.history.append({"role": "bot", "message": result})

                # Vider le champ de saisie
                st.session_state.user_input = ""

        # --------------------------
        # Champ de saisie
        # --------------------------
        st.text_input(
            "",
            key="user_input",
            placeholder="Tapez votre question et appuyez sur Entr√©e",
            on_change=send_message,
            label_visibility="collapsed"
        )
